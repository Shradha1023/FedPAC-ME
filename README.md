# Federated Learning Framework for Medical Image Analysis with Perspective-Aware Contrastive and Mixture of Experts (FedPAC-ME)
This repository contains the official implementation of FedPAC-ME, a federated learning framework that integrates Multi-Perspective Contrastive Learning (MPCL) with a Mixture-of-Experts (ME) personalization module to achieve robust, privacy-preserving medical image segmentation across heterogeneous clients.

The code supports federated training with labeled and unlabeled data, multi-perspective augmentations, contrastive alignment, and client-specific expert routing. It is built for reproducibility and fully aligned with the code policies of Nature Scientific Reports.

# ğŸ§  Overview
This repository contains the source code used to implement the FedPAC-ME framework described in the associated manuscript. The framework integrates (i) multi-perspective contrastive learning for representation alignment and (ii) a mixture-of-experts module for client-specific personalization within a federated learning environment. The codebase supports semi-supervised training using both labeled and unlabeled medical imaging data and is designed to operate under heterogeneous (non-IID) client distributions.

All experiments presented in the manuscript can be reproduced using the scripts and configuration files provided here.

# ğŸ“ Repository Structure
````
FedPAC-ME/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ federated/           # Federated training procedures and aggregation rules
â”‚   â”œâ”€â”€ models/              # Model architectures including MPCL and ME modules
â”‚   â”œâ”€â”€ contrastive/         # Contrastive loss functions and augmentation routines
â”‚   â”œâ”€â”€ utils/               # Data loading, preprocessing, metrics, logging
â”‚   â”œâ”€â”€ evaluation/          # Evaluation scripts and statistical analysis
â”‚   â””â”€â”€ main.py              # Main training and experiment entry point
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ fed_config.yaml      # Federated learning configuration parameters
â”‚   â”œâ”€â”€ model_config.yaml    # Model-specific hyperparameters
â”‚   â””â”€â”€ data_config.yaml     # Dataset paths and augmentation settings
â”‚
â”œâ”€â”€ data/                    # Placeholder for datasets (not included)
â”‚
â”œâ”€â”€ requirements.txt         # Python dependency list
â””â”€â”€ README.md

````

# âš™ï¸ Installation
## ğŸš€ Environment Setup

````

- Python â‰¥ 3.8  
- PyTorch â‰¥ 1.12  

```bash
git clone https://github.com/yourusername/FedPAC-ME.git
cd FedPAC-ME
python -m venv fedpacme_env
source fedpacme_env/bin/activate      # Linux/macOS  
fedpacme_env\Scripts\activate         # Windows
pip install -r requirements.txt

````

## ğŸ—‚ï¸ Dataset Preparation
Datasets are not included in this repository. Users should:

Download the dataset(s) used in the manuscript
Place the files under the data/ directory or specify alternative paths in configs/data_config.yaml.
If federated partitioning is required, specify the number of clients, labeled/unlabeled ratios, and distribution settings in the YAML configuration.
Running Experiments
Federated Training
To reproduce the main experimental results:
```
python src/main.py --config configs/fed_config.yaml
```
# ğŸ“Š Evaluation Procedures
To evaluate a trained global model:
```
python src/evaluation/eval.py --checkpoint path/to/model.pth
```
# ğŸ” Reproducibility
All random seeds used in the manuscript can be set via command-line arguments or within the configuration files. To reproduce the exact experimental conditions:
```
python src/main.py --config configs/fed_config.yaml --seed 42
```
# ğŸ“Œ Citation
Please cite the associated manuscript when using this repository:

```
Federated Learning Framework for Medical Image Analysis with Perspective-Aware Contrastive and Mixture of Experts
K. Hemalatha, Shradhanjali Das
Scientific Reports (Nature)
DOI: To be announced
```

# ğŸ“œ License
This repository is intended for **academic and research use only**.

Please see the `LICENSE` file for details.





