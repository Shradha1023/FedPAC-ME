# Federated Learning Framework for Medical Image Analysis with Perspective-Aware Contrastive and Mixture of Experts (FedPAC-ME)
This repository contains the official implementation of FedPAC-ME, a federated learning framework that integrates Multi-Perspective Contrastive Learning (MPCL) with a Mixture-of-Experts (ME) personalization module to achieve robust, privacy-preserving medical image segmentation across heterogeneous clients.

The code supports federated training with labeled and unlabeled data, multi-perspective augmentations, contrastive alignment, and client-specific expert routing. It is built for reproducibility and fully aligned with the code policies of Nature Scientific Reports.

## ğŸ§  Overview
This repository contains the official implementation of FedPAC-ME, a federated learning framework designed for multi-modal medical image analysis. The project includes data preprocessing, visualization, model development, and federated training for 3D MRI volumes such as those in the BraTS2020 dataset.

FedPAC-ME integrates:

    Perspective-Aware Contrastive Learning (PAC-L)
    Mixture of Experts (ME) for personalization
    Federated Aggregation (FedAvg-based)
    Multi-modal image processing for T1, T1ce, T2, and FLAIR

This repository supports all the preprocessing and visualization techniques demonstrated in the Google Colab.

## ğŸš€ Features

Automatic download and extraction of multi-modal MRI datasets

Advanced visualization:

1. 2D slices
2. Multi-modality grids
3. Segmentation mask overlays
4. 3D volumetric rendering
   
Preprocessing pipeline:

1. Normalization
2. Smoothing
3. Resampling
4. Slice-wise extraction

Federated Learning components (simulation-ready)

All experiments presented in the manuscript can be reproduced using the scripts and configuration files provided here.

# ğŸ“ Repository Structure
````
ğŸ“¦ FedPAC-ME/
â”‚
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ download.py
â”‚   â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”œâ”€â”€ preprocess/
â”‚   â”‚   â”œâ”€â”€ dataloaders.py
â”‚   â”‚   â”œâ”€â”€ dataset.py
â”‚   â”‚   â””â”€â”€ split_clients.py
â”‚   â”œâ”€â”€ visualization/
â”‚   â”‚   â”œâ”€â”€ visualize_slices.py
â”‚   â”‚   â”œâ”€â”€ plot_modalities.py
â”‚   â”‚   â”œâ”€â”€ histogram_plots.py
â”‚   â”‚   â””â”€â”€ segmentation_plots.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ attention.py
â”‚   â”‚   â”œâ”€â”€ attention_contrastive_model.py
â”‚   â”‚   â”œâ”€â”€ loss.py
â”‚   â”‚   â”œâ”€â”€ moe.py
â”‚   â”‚   â””â”€â”€ mpda.py
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ losses.py
â”‚   â”‚   â””â”€â”€ metrics.py
â”‚   â””â”€â”€ federated/
â”‚       â”œâ”€â”€ fedavg.py
â”‚       â”œâ”€â”€ client_simulator.py
â”‚       â””â”€â”€ aggregation.py
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ plots/
â”‚   â””â”€â”€ dataset/
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

````

## âš™ï¸ Installation

1. Clone the repository
````
git clone https://github.com/yourusername/FedPAC-ME.git
cd FedPAC-ME
````
3. Install dependencies
````
pip install -r requirements.txt
````
## ğŸš€ Environment Setup

````

- Python â‰¥ 3.8  
- PyTorch â‰¥ 1.12  

```bash
git clone https://github.com/yourusername/FedPAC-ME.git
cd FedPAC-ME
python -m venv fedpacme_env
source fedpacme_env/bin/activate      # Linux/macOS  
fedpacme_env\Scripts\activate         # Windows
pip install -r requirements.txt

````

## ğŸ“¥ Dataset Preparation
Datasets are not included in this repository. Users should:

Download the dataset(s) used in the manuscript
Place the files under the data/ directory or specify alternative paths in configs/data_config.yaml.
If federated partitioning is required, specify the number of clients, labeled/unlabeled ratios, and distribution settings in the YAML configuration.
Running Experiments
Federated Training
To reproduce the main experimental results:
```
python src/main.py --config configs/fed_config.yaml
```


# ğŸ“Š Evaluation Procedures
To evaluate a trained global model:
```
python src/evaluation/eval.py --checkpoint path/to/model.pth
```
# ğŸ” Reproducibility
All random seeds used in the manuscript can be set via command-line arguments or within the configuration files. To reproduce the exact experimental conditions:
```
python src/main.py --config configs/fed_config.yaml --seed 42
```
# ğŸ“Œ Citation
Please cite the associated manuscript when using this repository:

```
Federated Learning Framework for Medical Image Analysis with Perspective-Aware Contrastive and Mixture of Experts
K. Hemalatha, Shradhanjali Das
Scientific Reports (Nature)
DOI: To be announced
```

# ğŸ“œ License
This repository is intended for **academic and research use only**.

Please see the `LICENSE` file for details.





